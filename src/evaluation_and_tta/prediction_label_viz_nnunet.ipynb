{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e596b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "from termcolor import colored\n",
    "\n",
    "# project_root = '/d/hpc/projects/FRI/jf73497/aimi-project/src/segformer3duls/'\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.insert(0, project_root)\n",
    "\n",
    "# from metrics.competition_metric import ULS23_evaluator\n",
    "\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "import nnunetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8259a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./MIX_06966_0000.nii.gz\"\n",
    "label_path = \"./MIX_06966.nii.gz\"\n",
    "\n",
    "\n",
    "# Read image slice (single slice)\n",
    "image_itk = sitk.ReadImage(image_path)\n",
    "image_raw = sitk.GetArrayFromImage(image_itk).astype(np.float32)\n",
    "image_spacings = image_itk.GetSpacing()\n",
    "# Read full label volume\n",
    "label_itk = sitk.ReadImage(label_path)\n",
    "label = sitk.GetArrayFromImage(label_itk).astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135c772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def visualize_middle_slice_with_border(voi, prediction, label, pred_os):\n",
    "    \"\"\"\n",
    "    Visualize the middle slice of a VOI with border-only overlays for prediction and label.\n",
    "\n",
    "    Args:\n",
    "        voi (torch.Tensor): Input VOI of shape (1, 1, 64, 128, 128)\n",
    "        prediction (torch.Tensor): Binary prediction of the same shape\n",
    "        label (torch.Tensor): Binary ground truth label of the same shape\n",
    "    \"\"\"\n",
    "    assert voi.shape == prediction.shape == label.shape, \"Shapes must match and be (1, 1, 64, 128, 128)\"\n",
    "\n",
    "    # Convert tensors to NumPy arrays\n",
    "    voi_np = voi\n",
    "    pred_np = prediction.astype(np.uint8)\n",
    "    label_np = label.astype(np.uint8)\n",
    "    pred_os = pred_os.astype(np.uint8)\n",
    "\n",
    "    # Get the middle slice along the depth dimension\n",
    "    mid_slice = voi_np.shape[0] // 2\n",
    "    base_slice = voi_np[mid_slice]\n",
    "    pred_slice = pred_np[mid_slice]\n",
    "    label_slice = label_np[mid_slice]\n",
    "    pred_os = pred_os[mid_slice]\n",
    "\n",
    "    # Define edge detection kernel (simple Laplacian)\n",
    "    kernel = np.array([[1, 1, 1],\n",
    "                       [1, -8, 1],\n",
    "                       [1, 1, 1]], dtype=np.int8)\n",
    "\n",
    "    def extract_border(binary_slice):\n",
    "        padded = np.pad(binary_slice, pad_width=1, mode='constant', constant_values=0)\n",
    "        border = np.zeros_like(binary_slice)\n",
    "        for i in range(binary_slice.shape[0]):\n",
    "            for j in range(binary_slice.shape[1]):\n",
    "                region = padded[i:i+3, j:j+3]\n",
    "                val = np.sum(region * kernel)\n",
    "                border[i, j] = 1 if val != 0 and binary_slice[i, j] == 1 else 0\n",
    "        return border\n",
    "\n",
    "    # Extract borders\n",
    "    pred_border = extract_border(pred_slice)\n",
    "    label_border = extract_border(label_slice)\n",
    "    pred_os = extract_border(pred_os)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(base_slice, cmap=\"gray\")\n",
    "\n",
    "    # Overlay label border (red)\n",
    "    y_label, x_label = np.where(label_border == 1)\n",
    "    plt.scatter(x_label, y_label, c='#FF3F33', s=2, label='Label Border')\n",
    "\n",
    "    # Overlay prediction border (blue)\n",
    "    y_pred, x_pred = np.where(pred_border == 1)\n",
    "    plt.scatter(x_pred, y_pred, c='#3D3BF3', s=2, label='Prediction Border')\n",
    "\n",
    "    # Overlay prediction border (blue)\n",
    "    y_pred, x_pred = np.where(pred_os == 1)\n",
    "    plt.scatter(x_pred, y_pred, c='#FF9B17', s=2, label='OS Prediction Border')\n",
    "\n",
    "    # Legend and formatting\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='none', edgecolor='#FF3F33', label='Label Border'),\n",
    "        Patch(facecolor='none', edgecolor='#3D3BF3', label='SegFormer3D Prediction Border'),\n",
    "        Patch(facecolor='none', edgecolor='#FF9B17', label='SegFormer3D_OS Prediction Border'),\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='lower right')\n",
    "    plt.title(\"nnUNetv2 Middle Z Slice Predictions\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./nnunet_lesion_viz.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb584d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# evaluator = ULS23_evaluator()\n",
    "\n",
    "##################################################################################################\n",
    "def seed_everything(sedd) -> None:\n",
    "    seed = sedd\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def _run_eval(model, data, image_spacings) -> None:\n",
    "    \"\"\"_summary_\"\"\"\n",
    "    # Tell wandb to watch the model and optimizer values\n",
    "\n",
    "    print(\"[info] -- Starting model evaluation\")\n",
    "\n",
    "    predicted = model.predict_single_npy_array(data, {'spacing': image_spacings})\n",
    "    # print(logits.shape)\n",
    "    # predicted = torch.sigmoid(logits)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d9be59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128)\n",
      "(1, 64, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(image_raw.shape)\n",
    "\n",
    "model_input_image_raw = image_raw[None, ]\n",
    "print(model_input_image_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1ac684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] -- Running evaluation only.\n",
      "[info] -- Starting model evaluation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set seed\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    # Set up the nnUNetPredictor\n",
    "    predictor = nnUNetPredictor(\n",
    "        tile_step_size=0.5,\n",
    "        use_gaussian=True,\n",
    "        use_mirroring=False, # False is faster but less accurate\n",
    "        device=torch.device(type='cuda', index=0),\n",
    "        verbose=False,\n",
    "        verbose_preprocessing=False,\n",
    "        allow_tqdm=False\n",
    "    )\n",
    "    # Initialize the network architecture, loads the checkpoint\n",
    "    predictor.initialize_from_trained_model_folder(\n",
    "        fr\"C:\\Users\\Lazar\\OneDrive\\Desktop\\RU Courses\\AI in Medical Imaging\\project\\aimi-project\\SegFormer3D-main\\data\\local_data\\nnUNetTrainer_ULS_400_QuarterLR__nnUNetResEncUNetMPlans__3d_fullres\", # Path always relative to /opt/ml/model/\n",
    "        use_folds=[0],\n",
    "        checkpoint_name=\"checkpoint_best.pth\", # TODO: export the best checkpoint from the training job and change this to checkpoint_best.pth\n",
    "    )\n",
    "    return predictor\n",
    "\n",
    "predictor = load_model()\n",
    "\n",
    "\n",
    "print(\"[info] -- Running evaluation only.\")\n",
    "prediction_raw = _run_eval(predictor, model_input_image_raw, image_spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d876e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_mask_raw = prediction_raw > 0.5\n",
    "print(prediction_mask_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4aa95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(prediction_mask_raw.shape)\n",
    "plt.imshow(prediction_mask_raw[32])\n",
    "plt.savefig('./afaafa.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5980dc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128) (64, 128, 128) (64, 128, 128)\n",
      "(64, 128, 128) (64, 128, 128) (64, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(image_raw.shape, prediction_mask_raw.shape, label.shape)\n",
    "\n",
    "\n",
    "image_viz = image_raw\n",
    "preD_viz = prediction_mask_raw\n",
    "preD_viz_raw = prediction_mask_raw\n",
    "label_viz = label\n",
    "print(image_viz.shape, preD_viz.shape, label_viz.shape)\n",
    "visualize_middle_slice_with_border(image_viz, preD_viz_raw, label_viz, preD_viz_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef3f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x1467d80cfd00>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1467d80763e0, raw_cell=\"os.getcwd()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2Bhpc-login1.arnes.si/d/hpc/home/jf73497/projects/aimi-project/src/prediction_label_viz.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/d/hpc/projects/FRI/jf73497/aimi-project'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x1467d80cfd00>> (for post_run_cell), with arguments args (<ExecutionResult object at 1467d8076d10, execution_count=127 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1467d80763e0, raw_cell=\"os.getcwd()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2Bhpc-login1.arnes.si/d/hpc/home/jf73497/projects/aimi-project/src/prediction_label_viz.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D> result='/d/hpc/projects/FRI/jf73497/aimi-project'>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "250c20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(prediction_mask_raw, \"pred_non_os_nnunet.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
